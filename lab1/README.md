# Лабораторная работа №1
## Параллельные вычисления и пределы масштабирования

---

## 1. Введение

**Вариант**: 0 — Оценка вероятности разорения (Gambler's Ruin)

Цель работы — изучить влияние числа потоков на производительность параллельной программы, измерить ускорение и эффективность масштабирования относительно последовательного решения, а также исследовать, как общий или раздельный доступ потоков к входным данным влияет на результат. Задача — Monte Carlo-моделирование вероятности разорения при различных параметрах игры.

---

## 2. Задача

**Задача о разорении игрока (Gambler's Ruin)**: игрок начинает с начальным капиталом `k`, на каждом шаге выигрывает 1 с вероятностью `p` или проигрывает 1 с вероятностью `1 − p`. Игра заканчивается, когда капитал достигает 0 (разорение) или целевого значения `N` (победа). Задача — оценить вероятность разорения методом Монте-Карло, усреднив исходы по `M` независимым играм.

Аналитическое решение при `p ≠ 0.5`:

```
P(разорение | k) = (1 − (p/(1−p))^k) / (1 − (p/(1−p))^N)
```

Monte Carlo-оценка вычисляется по сетке параметров `(k, p)`:

| Параметр | Описание | Значения |
|----------|----------|----------|
| `k` | Начальный капитал | 10, 20, 30, 40, 50 |
| `p` | Вероятность выигрыша за ход | 0.30, 0.40, 0.45, 0.50, 0.55, 0.60, 0.70 |
| `N` | Целевой капитал (победа) | 100 |
| `M` | Количество игр на конфигурацию | 2000 |

Итого: **35 конфигураций** (5 × 7) на каждый входной файл. Одна итерация бенчмарка — обход всех 35 конфигураций, в сумме 70 000 игр.

---

## 3. Запуск

```bash
# Создать и активировать виртуальное окружение с зависимостями
python3 -m venv env
source env/bin/activate
pip install -r requirements.txt

# Запустить полный пайплайн (сборка + бенчмарк + графики)
chmod +x run.sh
./run.sh
```

`run.sh` последовательно:
1. Генерирует входные данные (`data/*.bin`), если их нет
2. Собирает проект через CMake в `build/` с флагами `-O3 -g -fno-omit-frame-pointer`
3. Запускает `bench_sequential` и `bench_parallel` на **одних данных** (`same_data.bin`) → `results/same_data.csv`
4. Запускает те же бенчмарки на **разных данных** (`seq_data.bin` / `parallel_data.bin`) → `results/diff_data.csv`
5. Строит 6 графиков через `draw_plots.py`

### Переменные окружения

| Переменная | Описание |
|------------|----------|
| `BENCH_SEQ_DATA` | Путь к бинарному файлу с конфигурациями для sequential |
| `BENCH_PAR_DATA` | Путь к бинарному файлу с конфигурациями для parallel |
| `BENCH_OUTPUT_CSV` | CSV-файл для записи результатов итерации |

### Запуск в Docker

```bash
docker build -t lab1-bench .
docker run --rm --privileged -v $(pwd):/app lab1-bench
```

> **Примечание по CPU Scaling**: при запуске на хосте Google Benchmark может выдать предупреждение о включённом масштабировании частоты CPU. Чтобы его убрать:
> ```bash
> echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
> ```

---

## 4. Реализация

### Формат данных

Бинарный файл: `int64_t` (число конфигураций) + массив структур `Config` по 16 байт каждая:

```cpp
struct Config {
    int32_t initial_capital;  // k: начальный капитал
    float   win_prob;         // p: вероятность выигрыша
    int32_t target;           // N: целевой капитал
    int32_t num_games;        // M: игр на конфигурацию
};
```

Генерация (Python):
```python
for k in [10, 20, 30, 40, 50]:
    for p in [0.30, 0.40, 0.45, 0.50, 0.55, 0.60, 0.70]:
        f.write(struct.pack("<ifii", k, p, 100, 2000))
```

### Последовательная реализация

Один поток обходит все `M` игр для каждой конфигурации подряд. ГПСЧ инициализируется детерминированным seed'ом (равным индексу конфигурации):

```cpp
static double simulate_ruin_seq(const Config& cfg, uint64_t seed)
{
    std::mt19937_64 rng(seed);
    std::bernoulli_distribution flip(cfg.win_prob);

    int ruined = 0;
    for (int g = 0; g < cfg.num_games; ++g) {
        int capital = cfg.initial_capital;
        while (capital > 0 && capital < cfg.target)
            capital += flip(rng) ? 1 : -1;
        if (capital == 0) ++ruined;
    }
    return static_cast<double>(ruined) / cfg.num_games;
}
```

### Параллельная реализация

`M` игр конфигурации делятся на равные чанки по числу потоков. Поток `t` использует seed `config_seed + t`, что обеспечивает детерминированность и независимость RNG потоков без мьютексов. После завершения всех потоков локальные счётчики суммируются:

```cpp
static double simulate_ruin_par(const Config& cfg,
                                uint64_t seed,
                                size_t num_threads)
{
    const int chunk = (cfg.num_games + num_threads - 1) / num_threads;
    std::vector<int> local_ruined(num_threads, 0);
    std::vector<std::thread> threads;

    for (size_t t = 0; t < num_threads; ++t) {
        const int begin = t * chunk;
        const int end   = std::min(begin + chunk, cfg.num_games);
        if (begin >= end) break;

        threads.emplace_back([&, t, begin, end]() {
            std::mt19937_64 rng(seed + t);
            std::bernoulli_distribution flip(cfg.win_prob);
            int ruined = 0;
            for (int g = begin; g < end; ++g) {
                int capital = cfg.initial_capital;
                while (capital > 0 && capital < cfg.target)
                    capital += flip(rng) ? 1 : -1;
                if (capital == 0) ++ruined;
            }
            local_ruined[t] = ruined;
        });
    }

    for (auto& th : threads) th.join();

    int total = 0;
    for (int r : local_ruined) total += r;
    return static_cast<double>(total) / cfg.num_games;
}
```

### Параметры бенчмарка

| Параметр | Значение |
|----------|----------|
| Итерации | 150 |
| Таймер | ручной (`UseManualTime`) |
| Потоки (parallel) | 2, 4, 8, 16, 32, 64, 128 |
| Единица времени | микросекунды |

Последовательный бенчмарк всегда выполняется в одном потоке и служит базой для расчёта ускорения и эффективности.

---

## 5. Эксперименты

Для каждого CSV строятся три графика:
- **Время** — bar chart: ось X = число потоков, ось Y = среднее время в секундах; пунктиром показано время sequential.
- **Ускорение** — line chart: `S(p) = T_seq / T_par(p)`, sequential закреплён в точке (1, 1.0).
- **Эффективность** — line chart: `E(p) = S(p) / p`, sequential закреплён в точке (1, 1.0).

Выбросы отсекаются по квантилям [1%, 99%] перед усреднением.

### Эксперимент 1: одни данные (same data)

Sequential и parallel читают один и тот же файл `same_data.bin`.

![Время выполнения](plots/same_data_time.png)

![Ускорение](plots/same_data_speedup.png)

![Эффективность](plots/same_data_efficiency.png)

### Эксперимент 2: разные данные (different data)

Sequential читает `seq_data.bin`, parallel — `parallel_data.bin`. Файлы содержат одинаковые конфигурации, но генерируются независимо, что устраняет возможное взаимодействие потоков через кеш при чтении общего файла.

![Время выполнения](plots/diff_data_time.png)

![Ускорение](plots/diff_data_speedup.png)

![Эффективность](plots/diff_data_efficiency.png)

---

## 6. Выводы

- **Ускорение реально, но нелинейно.** При переходе от 1 потока к 2–8 потокам время выполнения заметно снижается. При дальнейшем росте числа потоков прирост замедляется — согласно закону Амдала, последовательная часть (создание потоков, сбор результатов) ограничивает максимально достижимое ускорение.

- **Эффективность монотонно убывает.** Наибольшая эффективность достигается при наименьшем числе потоков: каждый поток получает максимальный чанк работы, а накладные расходы на запуск и синхронизацию минимальны. При 64–128 потоках накладные расходы на создание `std::thread` становятся сравнимы с полезной работой.

- **Влияние общих данных минимально.** В данной задаче входные данные читаются однократно до старта бенчмарка и кешируются в RAM, поэтому разницы между экспериментами «same data» и «different data» практически нет. Это подтверждает, что узкое место — вычисления, а не доступ к данным.

- **Детерминированность.** Использование seed'а вида `config_seed + thread_id` гарантирует воспроизводимые результаты при любом числе потоков без блокировок: каждый поток работает со своей независимой последовательностью псевдослучайных чисел.

- **Оптимальная точка** при данном размере задачи (35 конфигураций × 2000 игр) находится в районе 8–16 потоков — дальнейшее добавление потоков не окупается из-за overhead'а `std::thread`.
